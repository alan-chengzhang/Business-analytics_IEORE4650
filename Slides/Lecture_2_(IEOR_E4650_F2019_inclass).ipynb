{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture 2 (IEOR E4650 F2019 inclass).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s5izpSul0F9",
        "colab_type": "text"
      },
      "source": [
        "# **IEOR E4650  Business Analytics (Fall 2019)**\n",
        "\n",
        "##**Lecture 2: Programming Preparation**\n",
        "\n",
        "**Learning objective:**\n",
        "\n",
        "* able to import a dataset from csv saved on Google drive\n",
        "* able to understand the following three data structures: pandas series, dictionary, pandas dataframe\n",
        "* able to construct a pandas dataframe\n",
        "* able to perform simple data cleaning tasks using Pandas. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0IMUazMwY5O",
        "colab_type": "text"
      },
      "source": [
        "##Dataset in Business\n",
        "\n",
        "In a business setting, lots of datasets are already sitting in the warehouse. These datasets are very often stored following a two-dimensional structure.\n",
        "\n",
        "For example: \n",
        "\n",
        "\n",
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?id=13czV7gc-x26xSUzxkUilWpSXR20vIozB\" width=\"600\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "The above data gives the online shopping behavior of customers. Each row represents an observation, while each column lists the value of a specific feature. In the example, each observation tells us at a specific time, whether a specific customer viewed an  item, added an item to a chart, or did a transaction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-QBIqZHtmrX",
        "colab_type": "text"
      },
      "source": [
        "##Pandas: Data Analytics Package in Python \n",
        "\n",
        "<div>\n",
        "<img src=\"https://cdn.bulbagarden.net/upload/thumb/1/1c/674Pancham.png/500px-674Pancham.png\" width=\"150\"/>\n",
        "</div>\n",
        " \n",
        " \n",
        "Pandas (Python Data Analysis Library) provides high-performance data structures and data analysis tools for Python. Part of the learning objective of this course to teach you how to perform business analytics with help from Pandas.\n",
        "\n",
        "To study Pandas operations by yourself, [click this link](https://pandas.pydata.org/pandas-docs/stable/reference/index.html) for some good reference. We will also introduce some more pandas operations in the later lectures.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ykS0BmPbZ_u",
        "colab_type": "text"
      },
      "source": [
        "##Importing a dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-w27qlAnWIc",
        "colab_type": "text"
      },
      "source": [
        "For this course, we will mostly work with small/medium-sized dataset. However, the methods and models could be easily applied to larger datasets. The datasets for this course are stored in csv files. \n",
        "\n",
        "\n",
        "We will import the data to Jupyter Notebook as a Pandas dataframe object. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hojEGwM22JHW",
        "colab_type": "text"
      },
      "source": [
        "Step 1: **Import** the library, authenticate, and create the interface to csv files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nutu0nDx7qry",
        "colab_type": "code",
        "outputId": "e61fcce6-5ed9-4a90-98a3-9f1f34b6015e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 15.1MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 1.9MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 1.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.2MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 2.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 2.9MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 2.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 2.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 2.9MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2-0LMf-2S8G",
        "colab_type": "text"
      },
      "source": [
        "Step 2: Import the data from csv file as a DataFrame object\n",
        "\n",
        "*When working with your own csv file stored on Google drive, you simply need to get the sharable link and substitute the link. Also, rename myfile to the file name of your liking."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRzg652bVjNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "link=\"https://drive.google.com/open?id=17Sa-DuRFCWfPzCW6uRbPwxAyo1mQARUn\"\n",
        "_,id=link.split(\"=\")\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('myfile.csv')  \n",
        "import pandas as pd\n",
        "Sales = pd.read_csv('myfile.csv')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBDk04kql8li",
        "colab_type": "text"
      },
      "source": [
        "Now, let's take a look at the first few observations using head method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhFV-hCcmDZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VYk-G19nmHRQ"
      },
      "source": [
        "## Understand your data\n",
        "\n",
        "\n",
        "\n",
        "It is important to **KNOW YOUR DATA** before running any models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igMw7GwP8zxp",
        "colab_type": "text"
      },
      "source": [
        "###Data documentation\n",
        "Usually, data comes with some documentation, giving the background of the data and the details of each data field. Read it carefully before you proceed. As an analyst, make sure you maintain some documentation of your dataset. A simplified description of this dataset is as follows:\n",
        "\n",
        "---\n",
        "This dataset contains a sample of the building or building unit (apartment, etc.) sold in the New York City property market over a 12-month period with a sales price higher than 100,000 USD.\n",
        "\n",
        "Content\n",
        "This dataset contains the location, sale price, and some important properties of the building units sold. A reference on the trickier field:\n",
        "\n",
        "BOROUGH: A digit code for the borough the property is located in; in order, these are Manhattan (1), Bronx (2), Brooklyn (3), Queens (4), and Staten Island (5).\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuVlHWjA-OUp",
        "colab_type": "text"
      },
      "source": [
        "###Data attributes\n",
        "Carefully check the columns and rows. Understand what each column/row stands for. Each dataframe has several attributes. Exploring some of the attributes can help us quickly get to know the data. Here, the attributes are simply the properties of an object. \n",
        "  \n",
        "\n",
        "Some useful functions/methods\n",
        "\n",
        "|Function|Explanation|\n",
        "|---|---|\n",
        "|DataFrame.shape|Return a tuple representing the dimensionality of the DataFrame.|\n",
        "|DataFrame.columns|returns the column names of the data|\n",
        "|DataFrame.dtype|returns the data type of each column |\n",
        "\n",
        " When accessing an attribute for a dataframe, you can simply replace DataFrame using the name of your own data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OA8aXx181-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M-lSTez84iP",
        "colab_type": "text"
      },
      "source": [
        "Get the column names of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OTYfDzR86S6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hul816U79Qgd",
        "colab_type": "text"
      },
      "source": [
        "Checking the data type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "howDcJjX9a4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIWvhxUJvHE4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "The above is self-explanatory. \n",
        "\n",
        "* `int64` indicates that data in the column are integer numbers\n",
        "* `float64` indicates that data in the column are float numbers\n",
        "* `object` indicates that data in the column are strings\n",
        "\n",
        "The following table shows commonly used data types in the dataframe.\n",
        "\n",
        "|Pandas dtype|Corresponding Python type| Usage|\n",
        "|---|---|---|\n",
        "|object|\tstr\t|\tText|\n",
        "|int64|\tint\t|Integer numbers|\n",
        "|float64|\tfloat|Floating point numbers|\n",
        "|bool|\tbool| True/False (Boolean) values|\n",
        "|datetime64|\tNA\t|Date and time values|\n",
        "|category|\tNA\t|Finite list of text values|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3LyzlUUHEbp",
        "colab_type": "text"
      },
      "source": [
        "##Create sub-tables to include certain rows and columns\n",
        "\n",
        "There are cases we do not want to work with the whole dataset. Instead, we might only want to get specific columns or rows. Let's first talk about the labels and the indices of a dataframe.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFOVOT0-ua8l",
        "colab_type": "text"
      },
      "source": [
        "### Table Index and label\n",
        "\n",
        "Each row and column in the dataframe has its own **index** and **label**  \n",
        "\n",
        "**Index**\n",
        "\n",
        "(1) Indexing of a row\n",
        "\n",
        "Each row has its unique index, starting from zero.\n",
        "\n",
        "\n",
        "(2) Indexing of a column\n",
        "\n",
        "Each column has its unique index, starting from zero as well. \n",
        "\n",
        "\n",
        "\n",
        "**Label**\n",
        "\n",
        "(1) Label of a row\n",
        "\n",
        "each column has its unique label. It is given in the left-most column in bold font. Usually, it is the same as the index. \n",
        "\n",
        ">`DataFrame.index` method returns the labels of the rows\n",
        " \n",
        "\n",
        "(2) Label of a column\n",
        "\n",
        "each column has its unique label. It is given in the first row of the spreadsheet.\n",
        "\n",
        ">`DataFrame.columns` method returns the labels of the columns\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibFbWkdImJ-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylbLZQz-nU6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3I9Hr5jwxwE",
        "colab_type": "text"
      },
      "source": [
        "###Get certain columns based on labels\n",
        "\n",
        "We might be interested in keeping only certain columns.\n",
        "\n",
        "The direct way is to use\n",
        "\n",
        "`DataFrame[[\"column1\",\"column3\",...]]`\n",
        "\n",
        "where \"column1\", \"column3\", etc are the labels of the columns you want to select."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Clg6gsjgE0Yz",
        "colab_type": "text"
      },
      "source": [
        "For example, we can get the column  \"SALE_PRICE\" by using"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yD3UTJAE9yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwswOubtGUMc",
        "colab_type": "text"
      },
      "source": [
        "PS: If you only used single brackets to get a column, we will get Pandas series. Pandas series is a one-dimensional data structure in Pandas. It is very similar to the list/array we have seen before. However, each element has its label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ID4RHbBE9wg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L-fYOD3E0Sg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "**PRACTICE: Get a dataframe that includes the first column and the last column**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqlxra_RwxFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSwFSiRSxhVd",
        "colab_type": "text"
      },
      "source": [
        "###Get certain rows based on index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMXYTJev4FMu",
        "colab_type": "text"
      },
      "source": [
        "`DataFrame[begin:end:step]`\n",
        "\n",
        "If we want to select certain rows, we can use this command. `begin` indicates the index of the beginning rows we want to select, `end` indicates the index of the end row we want to select (but this record will not be included), step gives the difference in the indices between two adjacent rows selected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw8GGjAuxg70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTLdF5WWJA87",
        "colab_type": "text"
      },
      "source": [
        "###Get certain rows based on conditions\n",
        "We might only want to include certain rows that satisfy certain conditions. For example, we might want to only include units that sold for more than 1 million dollars. We can use Boolean array/list/series to help us do this.\n",
        "\n",
        "DataFrame[A]\n",
        "Where, A is a Boolean array/list/series, the length of which will be the same as the number of rows. True indicates the corresponding row will be kept, while False indicates the corresponding rows will be discarded.\n",
        "\n",
        "For example, the following command gives all the transactions with sales higher than 2 million dollars.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsZcowmdFrZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# or more compactly\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxxZEtuxG3Yz",
        "colab_type": "text"
      },
      "source": [
        "We can also use & (and) or | (or) to connect several conditions. For example, the following example keeps only properties with the number of units higher than 10 and lower than 20.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHp6ThsPIGK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5jatNGymxyR",
        "colab_type": "text"
      },
      "source": [
        "###More flexibility\n",
        "\n",
        "We can do our indexing using the following commands\n",
        "\n",
        "|Function|Explanation|\n",
        "|--|--|\n",
        "|[df.iloc[row_range1, column_range1]](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html)|Purely integer-location based indexing for selection by position|\n",
        "|[df.loc[row_range2, column_range2]](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc)|Access a group of rows and columns by label(s) or a boolean array.\n",
        "\n",
        "\n",
        "For iloc method, we should use a numpy array and list to give the **indices** of the columns and rows we would like to show.\n",
        "\n",
        "For loc method, we should use a numpy array and list to give the **labels** of the columns and rows we would like to show.\n",
        "\n",
        "In addition, if we use loc method, we can use a Boolean array/list/series filter out rows like we did above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_bV1Mx1NayV",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "**Practice: use iloc/loc method to do the following:**\n",
        "\n",
        "List the address information of all the properties sold between 1 million and 1.05 millions dollars.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s3_17qzG5id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVN2rWrl3PLg",
        "colab_type": "text"
      },
      "source": [
        "##Data Cleaning \n",
        "\n",
        "Data cleaning can be a tedious task. Lots of business analysts spend lots of time working on preparing the data. The 80/20 rule states that a analyst spends around 80% of the time doing data cleaning before even moving on analytics!\n",
        "\n",
        "\n",
        "Some of the important tasks related to data cleaning include \n",
        "* Checking **the validity of the values** \n",
        "* Checking for **missing** values\n",
        "* Checking  **unique values** (ID variables) are indeed unique\n",
        "* Combining **multiple** files\n",
        "* Checking for **duplicated** records\n",
        "* **Restructuring** the data\n",
        "* ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akJ8oUlz8e4E",
        "colab_type": "text"
      },
      "source": [
        "Pandas provides many powerful methods to help us perform data cleaning very efficiently. For a quick reference, click [here](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) for a nice cheatsheet.\n",
        "\n",
        "\n",
        "Let's illustrate some of the basic tasks using this sample data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aZU7BjcM9O6",
        "colab_type": "text"
      },
      "source": [
        "###Checking the validity of the values\n",
        "\n",
        "We want to check whether the values in the dataframe follows the specific requirement. For example, in our case, we have 5 Boroughs in NYC. Thus, we want to check whether the \"BOROUGH\" field only includes values equals 1, 2, 3, 4, 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4Nep_pEM8yU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Check the number of unique values\n",
        "\n",
        "\n",
        "#Check they are indeed 1-5. \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoNqbkZXOKWb",
        "colab_type": "text"
      },
      "source": [
        "For another example, we might not expect YEAR_BUILT to be within a specific range. We want to make sure of that.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4FgYvZmOlTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvqJygUpQNQY",
        "colab_type": "text"
      },
      "source": [
        "### Missing values\n",
        "\n",
        "One thing we immediately notice is that there are missing values in the dataset. Currently, they are represented using \"-\". In order to utilize functions/methods for missing values. We need to replace all the \"-\" with `np.nan`, which is a numpy format to denote missing value. We will use `DataFrame.replace()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geaF6UP8QMxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KVYmfV08eUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AoKNzY3XPRF",
        "colab_type": "text"
      },
      "source": [
        "Pandas provides many methods we can use to work with missing values. A good tutorial can be found [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html).\n",
        "\n",
        "\n",
        "Some commonly used methods are here\n",
        "\n",
        "|method|explanation|\n",
        "|---|---|\n",
        "|[DataFrame.isna() ](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#values-considered-missing)|Returns Boolean value for each cell indicating whether a number is a missing value (True) or not (False) |\n",
        "|[DataFrame.fillna() ](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#filling-missing-values-fillna)|Fill in the missing values with a specific method. For example backward, forward fill, mean, median, sum... |\n",
        "|[DataFrame.interpolate()](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#interpolation)|Fill in the missing values with more sophisticated  math methods |\n",
        "|[DataFrame.dropna()](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#dropping-axis-labels-with-missing-data-dropna)|Drop missing values|\n",
        "\n",
        "Let's give `DataFrame.isna()` a shot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikUnH3UwZN38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jUcnPWjUz9l",
        "colab_type": "text"
      },
      "source": [
        "How do we proceed?\n",
        "\n",
        "Maybe we are interested in understanding how many missing values we have. Now, it is a good place for us to talk about some basic Pandas calculations we can work on.\n",
        "\n",
        "|Function|Explanation|\n",
        "|---|---|\n",
        "|DataFrame.sum()|sum all the values column wise. add axis=1 if row-wise.|\n",
        "|DataFrame.cumsum()|Perform cumulative sum column wise. add axis=1 if row-wise.|\n",
        "|DataFrame.prod()|multiply all the values column wise. add axis=1 if row-wise.|\n",
        "|DataFrame.cumprod()|Perform cumulative multiplication column wise. add axis=1 if row-wise.|\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXz0F2ZRUznl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#or connecting both methods together\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThyyhAPYeJnM",
        "colab_type": "text"
      },
      "source": [
        "The last line connects two methods. This is called method chaining, which increases the readability. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opQpLgVwFw48",
        "colab_type": "text"
      },
      "source": [
        "Now, we can see that we have three features containing missing values. Especially, around 50% of the observations have **Gross_square_feet** and **Land_square_feet** being missing!\n",
        "\n",
        "It is important to know why missing values are there. \n",
        "\n",
        "(1) Mechanical value\n",
        "\n",
        "> The values are missing on purpose. For example, maybe some observations are expected to have missing value. For example, in the following survey, a missing value will be generated by design if a consumer states that he is not a \"cat\" person.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://help.surveyhero.com/wp-content/uploads/2017/02/skip-logic-e1487580662876.png\" width=\"200\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "(2) Real missing values\n",
        "\n",
        "Real missing values should have their values, but for some reasons, they are not recorded.\n",
        "\n",
        "\n",
        "Usually, people choose one of the following methods to deal with missing values. \n",
        "> delete all the observations that contain missing value.\n",
        "\n",
        "> fill in the missing values to our best knowledge. \n",
        "\n",
        "If the missing values happens randomly, dropping them will not introduce bias to the field with missing values, but decrease the sample size and dropping other information associated with those observations dropped. Method 2 might introduce bias to the field with missing values, but will keep the information of other features. \n",
        "\n",
        "\n",
        "If the missing values do not happen randomly, dropping them might cause bias. For example, assuming non-loyal customers are more likely to miss lots of missing information, deleting those records might cause loyal customers to be over-represented.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYRSrLCYR9Yc",
        "colab_type": "text"
      },
      "source": [
        "###Merging data\n",
        "\n",
        "Data can come from different sources. Thus, we will need to merge data based on certain keys.\n",
        "\n",
        "For example, maybe instead of using 1, 2, 3, 4, 5 to represent the 5 boroughs, we might want to replace them with the actual names. In other words, we want to \n",
        "\n",
        "* Create a new table like the follows\n",
        "\n",
        "|Borough|Borough Name|\n",
        "|---|---|\n",
        "|1|Manhattan|\n",
        "|2|Bronx|\n",
        "|3|Brooklyn|\n",
        "|4|Queens|\n",
        "|5|Staten Island|\n",
        "\n",
        "* Merge two tables\n",
        "\n",
        "* Drop \"Borough\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BK-WkX0Va8L",
        "colab_type": "text"
      },
      "source": [
        "Let's first construct another table called \"Borough_data\".\n",
        "\n",
        "We create a dataframe from a **dictionary**. Dictionary is a data structure that stores a collection of keys and their corresponding values. The keys needs to be unique and can be defined using both numeric values and string values. In addition, each key will be corresponding to its associated values. Here, the values could pretty much follow any type. \n",
        "\n",
        "<div>\n",
        "<img src=\"https://developers.google.com/edu/python/images/dict.png\n",
        "\" width=\"300\"/>\n",
        "</div>\n",
        "[ref: https://developers.google.com/edu/python/dict-files] \n",
        "\n",
        "\n",
        "To define a dictionary, we will use the following syntax:\n",
        "\n",
        "{\"key1\":values1, \"key2\": values2}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O11CfahyT7zh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \"Manhattan\",\"Bronx\",\"Brooklyn\",\"Queens\",\"Staten Island\"\n",
        "\n",
        "Borough_dic={\"Borough\":[1,2,3,4,5], \"Borough Name\":[\"Manhattan\",\"Bronx\",\"Brooklyn\",\"Queens\",\"Staten Island\"]}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWB593ZkVsDr",
        "colab_type": "text"
      },
      "source": [
        "We then use `pd.DataFrame(dic_name)` function to create our dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ePB5SqpVzOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rhk0f5VV1HU",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "DataFrame.merge() method helps us merge two tables based on specific keys. For instructions on this, click[ here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Dnh6aunV-vL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06ep4p5HWApe",
        "colab_type": "text"
      },
      "source": [
        "In the end, we use `DataFrame.drop()` to drop the two columns I do not need anymore. For reference about \"drop\" method, click [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L2eyKhGV-sW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}